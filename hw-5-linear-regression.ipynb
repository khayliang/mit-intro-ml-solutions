{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "we now will try using a feature set to predict the miles-per-gallon (MPG) score for vehicles.\n",
    "\n",
    "- Two choices of feature set:\n",
    "1. `\n",
    "[cylinders=standard, displacement=standard, horsepower=standard, weight=standard, acceleration=standard, origin=one_hot]\n",
    "`\n",
    "2. `\n",
    "[cylinders=one_hot, displacement=standard, horsepower=standard, weight=standard, acceleration=standard, origin=one_hot]\n",
    "`\n",
    "- Polynomial features (we will construct the polynomial features after having standardized the input data) of orders 1-3\n",
    "\n",
    "- Different choices of the regularization parameter, $\\lambda$. Although, ideally, you would run a grid search over a large range of $\\lambda$, we will ask you to look at the choices $\\lambda={0.0,0.01,0.02,\\dots,0.1}$ for polynomial features of orders 1 and 2, and the choices $\\lambda={0,20,40,\\dots,200}$ for polynomial features of order 3 (as this is approximately where we found the optimal \n",
    "to lie).\n",
    "\n",
    "We will use 10-fold cross-validation to try all possible combinations of these feature choices and test which is best. We have attached a code file with some predefined methods that will be useful to you here. Alternatively, a google colab link may be found here. If you choose to use the code file, a more detailed description of the roles of the files is below:\n",
    "\n",
    "The file code_for_hw5.py contains functions, some of which will need to be filled in with your definitions from this homework. Your functions are then called by ridge_min, defined for you, which takes a dataset $(X,y)$ and a hyperparameter, $\\lambda$\n",
    "as input and returns \n",
    "and \n",
    "minimizing the ridge regression objective using SGD (this is the analogue of the svm_min function that you wrote for homework last week). The learning rate and number of iterations are fixed in this function, and should not be modified for the purpose of answering the below questions (although you should feel free to experiment with these if you are interested!). This function will then further be called by xval_learning_alg (also defined for you in the same file), which returns the average RMSE across all (here, 10) splits of your data when performing cross-validation. (Note that this RMSE is reported in standardized y units; to convert this to RMSE in mpg (miles per gallon), you should multiply this by the sigma returned by the hw5.std_y function call.)\n",
    "\n",
    "The file auto.py will be used to implement the auto data regression. The file contains code for creating the two feature sets that you are asked to work with here. Transforming those features further with make_polynomial_feature_fun, and running the cross-validation function, which uses your implementations in code_for_hw5.py (both from code_for_hw5.py), you should be able to answer the following questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import code_for_hw5 as hw5\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# Auto Data\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "# Returns a list of dictionaries.  Keys are the column names, including mpg.\n",
    "auto_data_all = hw5.load_auto_data('auto-mpg-regression.tsv')\n",
    "\n",
    "# The choice of feature processing for each feature, mpg is always raw and\n",
    "# does not need to be specified.  Other choices are hw5.standard and hw5.one_hot.\n",
    "# 'name' is not numeric and would need a different encoding.\n",
    "features1 = [('cylinders', hw5.standard),\n",
    "            ('displacement', hw5.standard),\n",
    "            ('horsepower', hw5.standard),\n",
    "            ('weight', hw5.standard),\n",
    "            ('acceleration', hw5.standard),\n",
    "            ('origin', hw5.one_hot)]\n",
    "\n",
    "features2 = [('cylinders', hw5.one_hot),\n",
    "            ('displacement', hw5.standard),\n",
    "            ('horsepower', hw5.standard),\n",
    "            ('weight', hw5.standard),\n",
    "            ('acceleration', hw5.standard),\n",
    "            ('origin', hw5.one_hot)]\n",
    "\n",
    "# Construct the standard data and label arrays\n",
    "#auto_data[0] has the features for choice features1\n",
    "#auto_data[1] has the features for choice features2\n",
    "#The labels for both are the same, and are in auto_values\n",
    "auto_data = [0, 0]\n",
    "auto_values = 0\n",
    "auto_data[0], auto_values = hw5.auto_data_and_values(auto_data_all, features1)\n",
    "auto_data[1], _ = hw5.auto_data_and_values(auto_data_all, features2)\n",
    "\n",
    "#standardize the y-values\n",
    "auto_values, mu, sigma = hw5.std_y(auto_values)\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# Analyze auto data\n",
    "#-------------------------------------------------------------------------------     \n",
    "        \n",
    "#Your code for cross-validation goes here\n",
    "#Make sure to scale the RMSE values returned by xval_learning_alg by sigma,\n",
    "#as mentioned in the lab, in order to get accurate RMSE values on the dataset\n",
    "raw = auto_data[0]\n",
    "proc = auto_data[1]\n",
    "\n",
    "ord_2_fun = hw5.make_polynomial_feature_fun(2)\n",
    "ord_3_fun = hw5.make_polynomial_feature_fun(3)\n",
    "\n",
    "raw_ord_2 = ord_2_fun(raw)\n",
    "raw_ord_3 = ord_3_fun(raw)\n",
    "\n",
    "proc_ord_2 = ord_2_fun(proc)\n",
    "proc_ord_3 = ord_3_fun(proc)\n",
    "\n",
    "lambda_set_1 = [0.01 * i for i in range(10)]\n",
    "lambda_set_2 = [20 * i for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data, order 1:\n",
      "Lambda =  0.0 , MSRE:  4.273494915921781\n",
      "Lambda =  0.01 , MSRE:  4.274398918807104\n",
      "Lambda =  0.02 , MSRE:  4.275353672761194\n",
      "Lambda =  0.03 , MSRE:  4.2763583225901955\n",
      "Lambda =  0.04 , MSRE:  4.277412024638627\n",
      "Lambda =  0.05 , MSRE:  4.278513946677476\n",
      "Lambda =  0.06 , MSRE:  4.279663267791888\n",
      "Lambda =  0.07 , MSRE:  4.280859178268503\n",
      "Lambda =  0.08 , MSRE:  4.28210087948252\n",
      "Lambda =  0.09 , MSRE:  4.2833875837845445\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw data, order 1:\")\n",
    "for l in lambda_set_1:\n",
    "    print(\"Lambda = \", l, \", MSRE: \", (hw5.xval_learning_alg(raw, auto_values, l, 10)[0,0] * sigma)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data, order 2:\n",
      "Lambda =  0.0 , MSRE:  4.026341188910578\n",
      "Lambda =  0.01 , MSRE:  4.027146506420445\n",
      "Lambda =  0.02 , MSRE:  4.028010167779058\n",
      "Lambda =  0.03 , MSRE:  4.028931097303629\n",
      "Lambda =  0.04 , MSRE:  4.029908234793271\n",
      "Lambda =  0.05 , MSRE:  4.030940535385005\n",
      "Lambda =  0.06 , MSRE:  4.032026969408457\n",
      "Lambda =  0.07 , MSRE:  4.033166522239322\n",
      "Lambda =  0.08 , MSRE:  4.03435819415174\n",
      "Lambda =  0.09 , MSRE:  4.0356010001696365\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw data, order 2:\")\n",
    "for l in lambda_set_1:\n",
    "    print(\"Lambda = \", l, \", MSRE: \", (hw5.xval_learning_alg(raw_ord_2, auto_values, l, 10)[0,0] * sigma)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data, order 3:\n",
      "Lambda =  0 , MSRE:  91158721.07809703\n",
      "Lambda =  20 , MSRE:  6.47860271837614\n",
      "Lambda =  40 , MSRE:  6.02418286672084\n",
      "Lambda =  60 , MSRE:  6.0393684475134535\n",
      "Lambda =  80 , MSRE:  6.03256196106872\n",
      "Lambda =  100 , MSRE:  6.031268805897686\n",
      "Lambda =  120 , MSRE:  6.0467535402561\n",
      "Lambda =  140 , MSRE:  6.078747854924028\n",
      "Lambda =  160 , MSRE:  6.127334353870603\n",
      "Lambda =  180 , MSRE:  6.197874066007316\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw data, order 3:\")\n",
    "for l in lambda_set_2:\n",
    "    print(\"Lambda = \", l, \", MSRE: \", (hw5.xval_learning_alg(raw_ord_3, auto_values, l, 10)[0,0] * sigma)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data, order 1:\n",
      "Lambda =  0.0 , MSRE:  4.141647982751426\n",
      "Lambda =  0.01 , MSRE:  4.1431706015045995\n",
      "Lambda =  0.02 , MSRE:  4.144758502018196\n",
      "Lambda =  0.03 , MSRE:  4.146410431383641\n",
      "Lambda =  0.04 , MSRE:  4.148125154638875\n",
      "Lambda =  0.05 , MSRE:  4.149901454621981\n",
      "Lambda =  0.06 , MSRE:  4.151738131821753\n",
      "Lambda =  0.07 , MSRE:  4.153634004225474\n",
      "Lambda =  0.08 , MSRE:  4.155587907164005\n",
      "Lambda =  0.09 , MSRE:  4.157598693154449\n"
     ]
    }
   ],
   "source": [
    "print(\"Processed data, order 1:\")\n",
    "for l in lambda_set_1:\n",
    "    print(\"Lambda = \", l, \", MSRE: \", (hw5.xval_learning_alg(proc, auto_values, l, 10)[0,0] * sigma)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data, order 2:\n",
      "Lambda =  0.0 , MSRE:  3.8843698498154873\n",
      "Lambda =  0.01 , MSRE:  3.8850942313094174\n",
      "Lambda =  0.02 , MSRE:  3.885868717942965\n",
      "Lambda =  0.03 , MSRE:  3.8866924082149437\n",
      "Lambda =  0.04 , MSRE:  3.8875644140235237\n",
      "Lambda =  0.05 , MSRE:  3.8884838605135204\n",
      "Lambda =  0.06 , MSRE:  3.889449885923863\n",
      "Lambda =  0.07 , MSRE:  3.890461641435335\n",
      "Lambda =  0.08 , MSRE:  3.8915182910185995\n",
      "Lambda =  0.09 , MSRE:  3.8926190112826013\n"
     ]
    }
   ],
   "source": [
    "print(\"Processed data, order 2:\")\n",
    "for l in lambda_set_1:\n",
    "    print(\"Lambda = \", l, \", MSRE: \", (hw5.xval_learning_alg(proc_ord_2, auto_values, l, 10)[0,0] * sigma)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data, order 3:\n",
      "Lambda =  0 , MSRE:  3741589.493776819\n",
      "Lambda =  20 , MSRE:  5.736581678599373\n",
      "Lambda =  40 , MSRE:  5.911374788231212\n",
      "Lambda =  60 , MSRE:  5.999429076453326\n",
      "Lambda =  80 , MSRE:  6.046741056275725\n",
      "Lambda =  100 , MSRE:  6.089451111698678\n",
      "Lambda =  120 , MSRE:  6.137299095585995\n",
      "Lambda =  140 , MSRE:  6.192891347950813\n",
      "Lambda =  160 , MSRE:  6.2567067751126615\n",
      "Lambda =  180 , MSRE:  6.329337221277677\n"
     ]
    }
   ],
   "source": [
    "print(\"Processed data, order 3:\")\n",
    "for l in lambda_set_2:\n",
    "    print(\"Lambda = \", l, \", MSRE: \", (hw5.xval_learning_alg(proc_ord_3, auto_values, l, 10)[0,0] * sigma)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
