{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Perceptron Algorithm\n",
    "## Setup\n",
    "The following cell contains boilerplate for the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Code for MIT 6.036 Homework 2\n",
    "'''\n",
    "# Implement perceptron, average perceptron\n",
    "\n",
    "import pdb\n",
    "import operator\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import colors\n",
    "\n",
    "######################################################################\n",
    "# Plotting\n",
    "\n",
    "def tidy_plot(xmin, xmax, ymin, ymax, center = False, title = None,\n",
    "                 xlabel = None, ylabel = None):\n",
    "    '''\n",
    "    Set up axes for plotting\n",
    "    xmin, xmax, ymin, ymax = (float) plot extents\n",
    "    Return matplotlib axes\n",
    "    '''\n",
    "    plt.ion()\n",
    "    plt.figure(facecolor=\"white\")\n",
    "    ax = plt.subplot()\n",
    "    if center:\n",
    "        ax.spines['left'].set_position('zero')\n",
    "        ax.spines['right'].set_color('none')\n",
    "        ax.spines['bottom'].set_position('zero')\n",
    "        ax.spines['top'].set_color('none')\n",
    "        ax.spines['left'].set_smart_bounds(True)\n",
    "        ax.spines['bottom'].set_smart_bounds(True)\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "    else:\n",
    "        ax.spines[\"top\"].set_visible(False)    \n",
    "        ax.spines[\"right\"].set_visible(False)    \n",
    "        ax.get_xaxis().tick_bottom()  \n",
    "        ax.get_yaxis().tick_left()\n",
    "    eps = .05\n",
    "    plt.xlim(xmin-eps, xmax+eps)\n",
    "    plt.ylim(ymin-eps, ymax+eps)\n",
    "    if title: ax.set_title(title)\n",
    "    if xlabel: ax.set_xlabel(xlabel)\n",
    "    if ylabel: ax.set_ylabel(ylabel)\n",
    "    return ax\n",
    "\n",
    "def plot_separator(ax, th, th_0):\n",
    "    '''\n",
    "    Plot separator in 2D\n",
    "    ax = (matplotlib plot) plot axis\n",
    "    th = (numpy array) theta\n",
    "    th_0 = (float) theta_0\n",
    "    '''\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    ymin,ymax = ax.get_ylim()\n",
    "    pts = []\n",
    "    eps = 1.0e-6\n",
    "    # xmin boundary crossing is when xmin th[0] + y th[1] + th_0 = 0\n",
    "    # that is, y = (-th_0 - xmin th[0]) / th[1]\n",
    "    if abs(th[1,0]) > eps:\n",
    "        pts += [np.array([x, (-th_0 - x * th[0,0]) / th[1,0]]) \\\n",
    "                                                        for x in (xmin, xmax)]\n",
    "    if abs(th[0,0]) > 1.0e-6:\n",
    "        pts += [np.array([(-th_0 - y * th[1,0]) / th[0,0], y]) \\\n",
    "                                                         for y in (ymin, ymax)]\n",
    "    in_pts = []\n",
    "    for p in pts:\n",
    "        if (xmin-eps) <= p[0] <= (xmax+eps) and \\\n",
    "           (ymin-eps) <= p[1] <= (ymax+eps):\n",
    "            duplicate = False\n",
    "            for p1 in in_pts:\n",
    "                if np.max(np.abs(p - p1)) < 1.0e-6:\n",
    "                    duplicate = True\n",
    "            if not duplicate:\n",
    "                in_pts.append(p)\n",
    "    if in_pts and len(in_pts) >= 2:\n",
    "        # Plot separator\n",
    "        vpts = np.vstack(in_pts)\n",
    "        ax.plot(vpts[:,0], vpts[:,1], 'k-', lw=2)\n",
    "        # Plot normal\n",
    "        vmid = 0.5*(in_pts[0] + in_pts[1])\n",
    "        scale = np.sum(th*th)**0.5\n",
    "        diff = in_pts[0] - in_pts[1]\n",
    "        dist = max(xmax-xmin, ymax-ymin)        \n",
    "        vnrm = vmid + (dist/10)*(th.T[0]/scale)\n",
    "        vpts = np.vstack([vmid, vnrm])\n",
    "        ax.plot(vpts[:,0], vpts[:,1], 'k-', lw=2)\n",
    "        # Try to keep limits from moving around\n",
    "        ax.set_xlim((xmin, xmax))\n",
    "        ax.set_ylim((ymin, ymax))\n",
    "    else:\n",
    "        print('Separator not in plot range')\n",
    "\n",
    "def plot_data(data, labels, ax = None, clear = False,\n",
    "                  xmin = None, xmax = None, ymin = None, ymax = None):\n",
    "    '''\n",
    "    Make scatter plot of data.\n",
    "    data = (numpy array)\n",
    "    ax = (matplotlib plot)\n",
    "    clear = (bool) clear current plot first\n",
    "    xmin, xmax, ymin, ymax = (float) plot extents\n",
    "    returns matplotlib plot on ax \n",
    "    '''\n",
    "    if ax is None:\n",
    "        if xmin == None: xmin = np.min(data[0, :]) - 0.5\n",
    "        if xmax == None: xmax = np.max(data[0, :]) + 0.5\n",
    "        if ymin == None: ymin = np.min(data[1, :]) - 0.5\n",
    "        if ymax == None: ymax = np.max(data[1, :]) + 0.5\n",
    "        ax = tidy_plot(xmin, xmax, ymin, ymax)\n",
    "\n",
    "        x_range = xmax - xmin; y_range = ymax - ymin\n",
    "        if .1 < x_range / y_range < 10:\n",
    "            ax.set_aspect('equal')\n",
    "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "    elif clear:\n",
    "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "        ax.clear()\n",
    "    else:\n",
    "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "    colors = np.choose(labels > 0, cv(['r', 'g']))[0]\n",
    "    ax.scatter(data[0,:], data[1,:], c = colors,\n",
    "                    marker = 'o', s=50, edgecolors = 'none')\n",
    "    # Seems to occasionally mess up the limits\n",
    "    ax.set_xlim(xlim); ax.set_ylim(ylim)\n",
    "    ax.grid(True, which='both')\n",
    "    #ax.axhline(y=0, color='k')\n",
    "    #ax.axvline(x=0, color='k')\n",
    "    return ax\n",
    "\n",
    "def plot_nonlin_sep(predictor, ax = None, xmin = None , xmax = None,\n",
    "                        ymin = None, ymax = None, res = 30):\n",
    "    '''\n",
    "    Must either specify limits or existing ax\n",
    "    Shows matplotlib plot on ax\n",
    "    '''\n",
    "    if ax is None:\n",
    "        ax = tidy_plot(xmin, xmax, ymin, ymax)\n",
    "    else:\n",
    "        if xmin == None:\n",
    "            xmin, xmax = ax.get_xlim()\n",
    "            ymin, ymax = ax.get_ylim()\n",
    "        else:\n",
    "            ax.set_xlim((xmin, xmax))\n",
    "            ax.set_ylim((ymin, ymax))\n",
    "\n",
    "    cmap = colors.ListedColormap(['black', 'white'])\n",
    "    bounds=[-2,0,2]\n",
    "    norm = colors.BoundaryNorm(bounds, cmap.N)            \n",
    "            \n",
    "    ima = np.array([[predictor(x1i, x2i) \\\n",
    "                         for x1i in np.linspace(xmin, xmax, res)] \\\n",
    "                         for x2i in np.linspace(ymin, ymax, res)])\n",
    "    im = ax.imshow(np.flipud(ima), interpolation = 'none',\n",
    "                       extent = [xmin, xmax, ymin, ymax],\n",
    "                       cmap = cmap, norm = norm)\n",
    "\n",
    "######################################################################\n",
    "#   Utilities\n",
    "\n",
    "def cv(value_list):\n",
    "    '''\n",
    "    Takes a list of numbers and returns a column vector:  n x 1\n",
    "    '''\n",
    "    return np.transpose(rv(value_list))\n",
    "\n",
    "def rv(value_list):\n",
    "    '''\n",
    "    Takes a list of numbers and returns a row vector: 1 x n\n",
    "    '''\n",
    "    return np.array([value_list])\n",
    "\n",
    "def y(x, th, th0):\n",
    "    '''\n",
    "    x is dimension d by 1\n",
    "    th is dimension d by 1\n",
    "    th0 is a scalar\n",
    "    return a 1 by 1 matrix\n",
    "    '''\n",
    "    return np.dot(np.transpose(th), x) + th0\n",
    "\n",
    "def positive(x, th, th0):\n",
    "    '''\n",
    "    x is dimension d by 1\n",
    "    th is dimension d by 1\n",
    "    th0 is dimension 1 by 1\n",
    "    return 1 by 1 matrix of +1, 0, -1\n",
    "    '''\n",
    "    return np.sign(y(x, th, th0))\n",
    "\n",
    "def score(data, labels, th, th0):\n",
    "    '''\n",
    "    data is dimension d by n\n",
    "    labels is dimension 1 by n\n",
    "    ths is dimension d by 1\n",
    "    th0s is dimension 1 by 1\n",
    "    return 1 by 1 matrix of integer indicating number of data points correct for\n",
    "    each separator.\n",
    "    '''\n",
    "    return np.sum(positive(data, th, th0) == labels)\n",
    "\n",
    "######################################################################\n",
    "#   Data Sets\n",
    "\n",
    "def super_simple_separable_through_origin():\n",
    "    '''\n",
    "    Return d = 2 by n = 4 data matrix and 1 x n = 4 label matrix\n",
    "    '''\n",
    "    X = np.array([[2, 3, 9, 12],\n",
    "                  [5, 1, 6, 5]])\n",
    "    y = np.array([[1, -1, 1, -1]])\n",
    "    return X, y\n",
    "\n",
    "def super_simple_separable():\n",
    "    '''\n",
    "    Return d = 2 by n = 4 data matrix and 1 x n = 4 label matrix\n",
    "    '''\n",
    "    X = np.array([[2, 3, 9, 12],\n",
    "                  [5, 2, 6, 5]])\n",
    "    y = np.array([[1, -1, 1, -1]])\n",
    "    return X, y\n",
    "\n",
    "def xor():\n",
    "    '''\n",
    "    Return d = 2 by n = 4 data matrix and 1 x n = 4 label matrix\n",
    "    '''\n",
    "    X = np.array([[1, 2, 1, 2],\n",
    "                  [1, 2, 2, 1]])\n",
    "    y = np.array([[1, 1, -1, -1]])\n",
    "    return X, y\n",
    "\n",
    "def xor_more():\n",
    "    '''\n",
    "    Return d = 2 by n = 4 data matrix and 1 x n = 4 label matrix\n",
    "    '''\n",
    "    X = np.array([[1, 2, 1, 2, 2, 4, 1, 3],\n",
    "                  [1, 2, 2, 1, 3, 1, 3, 3]])\n",
    "    y = np.array([[1, 1, -1, -1, 1, 1, -1, -1]])\n",
    "    return X, y\n",
    "\n",
    "# Test data for problem 2.1\n",
    "data1, labels1, data2, labels2 = \\\n",
    "(np.array([[-2.97797707,  2.84547604,  3.60537239, -1.72914799, -2.51139524,\n",
    "         3.10363716,  2.13434789,  1.61328413,  2.10491257, -3.87099125,\n",
    "         3.69972003, -0.23572183, -4.19729119, -3.51229538, -1.75975746,\n",
    "        -4.93242615,  2.16880073, -4.34923279, -0.76154262,  3.04879591,\n",
    "        -4.70503877,  0.25768309,  2.87336016,  3.11875861, -1.58542576,\n",
    "        -1.00326657,  3.62331703, -4.97864369, -3.31037331, -1.16371314],\n",
    "       [ 0.99951218, -3.69531043, -4.65329654,  2.01907382,  0.31689211,\n",
    "         2.4843758 , -3.47935105, -4.31857472, -0.11863976,  0.34441625,\n",
    "         0.77851176,  1.6403079 , -0.57558913, -3.62293005, -2.9638734 ,\n",
    "        -2.80071438,  2.82523704,  2.07860509,  0.23992709,  4.790368  ,\n",
    "        -2.33037832,  2.28365246, -1.27955206, -0.16325247,  2.75740801,\n",
    "         4.48727808,  1.6663558 ,  2.34395397,  1.45874837, -4.80999977]]), \n",
    " np.array([[-1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1.,\n",
    "        -1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
    "        -1., -1., -1., -1.]]), np.array([[ 0.6894022 , -4.34035772,  3.8811067 ,  4.29658177,  1.79692041,\n",
    "         0.44275816, -3.12150658,  1.18263462, -1.25872232,  4.33582168,\n",
    "         1.48141202,  1.71791177,  4.31573568,  1.69988085, -2.67875489,\n",
    "        -2.44165649, -2.75008176, -4.19299345, -3.15999758,  2.24949368,\n",
    "         4.98930636, -3.56829885, -2.79278501, -2.21547048,  2.4705776 ,\n",
    "         4.80481986,  2.77995092,  1.95142828,  4.48454942, -4.22151738],\n",
    "       [-2.89934727,  1.65478851,  2.99375325,  1.38341854, -4.66701003,\n",
    "        -2.14807131, -4.14811829,  3.75270334,  4.54721208,  2.28412663,\n",
    "        -4.74733482,  2.55610647,  3.91806508, -2.3478982 ,  4.31366925,\n",
    "        -0.92428271, -0.84831235, -3.02079092,  4.85660032, -1.86705397,\n",
    "        -3.20974025, -4.88505017,  3.01645974,  0.03879148, -0.31871427,\n",
    "         2.79448951, -2.16504256, -3.91635569,  3.81750006,  4.40719702]]),\n",
    " np.array([[-1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
    "        -1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,\n",
    "        -1.,  1.,  1.,  1.]]))\n",
    "\n",
    "# Test data for problem 2.2\n",
    "big_data, big_data_labels = (np.array([[-2.04297103, -1.85361169, -2.65467827, -1.23013149, -0.31934782,\n",
    "         1.33112127,  2.3297942 ,  1.47705445, -1.9733787 , -2.35476882,\n",
    "        -4.97193554,  3.49851995,  4.00302943,  0.83369183,  0.41371989,\n",
    "         4.37614714,  1.03536965,  1.2354608 , -0.7933465 , -3.85456759,\n",
    "         3.22134658, -3.39787483, -1.31182253, -2.61363628, -1.14618119,\n",
    "        -0.2174626 ,  1.32549116,  2.54520221,  0.31565661,  2.24648287,\n",
    "        -3.33355258, -0.98689271, -0.24876636, -3.16008017,  1.22353111,\n",
    "         4.77766994, -1.81670773, -3.58939471, -2.16268851,  2.88028351,\n",
    "        -3.42297827, -2.74992813, -0.40293356, -3.45377267,  0.62400624,\n",
    "        -0.35794507, -4.1648704 , -1.08734116,  0.22367444,  1.09067619,\n",
    "         1.28738004,  2.07442478,  4.61951855,  4.47029706,  2.86510481,\n",
    "         4.12532285,  0.48170777,  0.60089857,  4.50287515,  2.95549453,\n",
    "         4.22791451, -1.28022286,  2.53126681,  2.41887277, -4.9921717 ,\n",
    "         4.15022718,  0.49670572,  2.0268248 , -4.63475897, -4.20528418,\n",
    "         1.77013481, -3.45389325,  1.0238472 , -1.2735185 ,  4.75384686,\n",
    "         1.32622048, -0.13092625,  1.23457116, -1.69515197,  2.82027615,\n",
    "        -1.01140935,  3.36451016,  4.43762708, -4.2679604 ,  4.76734154,\n",
    "        -4.14496071, -4.38737405, -1.13214501, -2.89008477,  3.22986894,\n",
    "         1.84103699, -3.91906092, -2.8867831 ,  2.31059245, -3.62773189,\n",
    "        -4.58459406, -4.06343392, -3.10927054,  1.09152472,  2.99896855],\n",
    "       [-2.1071566 , -3.06450052, -3.43898434,  0.71320285,  1.51214693,\n",
    "         4.14295175,  4.73681233, -2.80366981,  1.56182223,  0.07061724,\n",
    "        -0.92053415, -3.61953464,  0.39577344, -3.03202474, -4.90408303,\n",
    "        -0.10239158, -1.35546287,  1.31372748, -1.97924525, -3.72545813,\n",
    "         1.84834303, -0.13679709,  1.36748822, -2.92886952, -2.48367819,\n",
    "        -0.0894489 , -2.99090327,  0.35494698,  0.94797491,  4.20393035,\n",
    "        -3.14009852, -4.86292242,  3.2964068 , -0.9911453 ,  4.39465   ,\n",
    "         3.64956975, -0.72225648, -0.15864119, -2.0340774 , -4.00758749,\n",
    "         0.8627915 ,  3.73237594, -0.70011824,  1.07566463, -4.05063547,\n",
    "        -3.98137177,  4.82410619,  2.5905222 ,  0.34188269, -1.44737803,\n",
    "         3.27583966,  2.06616486, -4.43584161,  0.27795053,  4.37207651,\n",
    "        -4.48564119,  0.7183541 ,  1.59374552, -0.13951634,  0.67825519,\n",
    "        -4.02423434,  4.15893861, -1.52110278,  2.1320374 ,  3.31118893,\n",
    "        -4.04072252,  2.41403912, -1.04635499,  3.39575642,  2.2189097 ,\n",
    "         4.78827245,  1.19808069,  3.10299723,  0.18927394,  0.14437543,\n",
    "        -4.17561642,  0.6060279 ,  0.22693751, -3.39593567,  1.14579319,\n",
    "         3.65449494, -1.27240159,  0.73111639,  3.48806017,  2.48538719,\n",
    "        -1.83892096,  1.42819622, -1.37538641,  3.4022984 ,  0.82757044,\n",
    "        -3.81792516,  2.77707152, -1.49241173,  2.71063994, -3.33495679,\n",
    "        -4.00845675,  0.719904  , -2.3257032 ,  1.65515972, -1.90859948]]), np.array([[-1., -1., -1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
    "         1., -1.,  1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1.,\n",
    "        -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,\n",
    "         1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
    "        -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,\n",
    "         1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,\n",
    "        -1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1., -1.,\n",
    "        -1., -1.,  1., -1., -1., -1., -1.,  1.,  1.]]))\n",
    "\n",
    "def gen_big_data():\n",
    "    '''\n",
    "    Return method that generates a dataset of input size n of X, y drawn from big_data\n",
    "    '''\n",
    "    nd = big_data.shape[1]\n",
    "    current = [0]\n",
    "    def f(n):\n",
    "        cur = current[0]\n",
    "        vals = big_data[:,cur:cur+n], big_data_labels[:,cur:cur+n]\n",
    "        current[0] += n\n",
    "        if current[0] >= nd: current[0] = 0\n",
    "        return vals\n",
    "    return f\n",
    "\n",
    "def gen_lin_separable(num_points=20, th=np.array([[3],[4]]), th_0=np.array([[0]]), dim=2):\n",
    "    ''' \n",
    "    Generate linearly separable dataset X, y given theta and theta0\n",
    "    Return X, y where\n",
    "    X is a numpy array where each column represents a dim-dimensional data point\n",
    "    y is a column vector of 1s and -1s\n",
    "    '''\n",
    "    X = np.random.uniform(low=-5, high=5, size=(dim, num_points))\n",
    "    y = np.sign(np.dot(np.transpose(th), X) + th_0)\n",
    "    return X, y\n",
    "\n",
    "def big_higher_dim_separable():\n",
    "    X, y = gen_lin_separable(num_points=50, dim=6, th=np.array([[3],[4],[2],[1],[0],[3]]))\n",
    "    return X, y\n",
    "\n",
    "def gen_flipped_lin_separable(num_points=20, pflip=0.25, th=np.array([[3],[4]]), th_0=np.array([[0]]), dim=2):\n",
    "    '''\n",
    "    Generate difficult (usually not linearly separable) data sets by\n",
    "    \"flipping\" labels with some probability.\n",
    "    Returns a method which takes num_points and flips labels with pflip\n",
    "    '''\n",
    "    def flip_generator(num_points=20):\n",
    "        X, y = gen_lin_separable(num_points, th, th_0, dim)\n",
    "        flip = np.random.uniform(low=0, high=1, size=(num_points,))\n",
    "        for i in range(num_points):\n",
    "            if flip[i] < pflip: y[0,i] = -y[0,i]\n",
    "        return X, y\n",
    "    return flip_generator\n",
    "\n",
    "######################################################################\n",
    "#   tests\n",
    "\n",
    "def test_linear_classifier(dataFun, learner, learner_params = {},\n",
    "                             draw = False, refresh = True, pause = False):\n",
    "    '''\n",
    "    Prints score of your classifier on given dataset\n",
    "    dataFun method that returns a dataset\n",
    "    learner your classifier method\n",
    "    learner_params parameters for the learner\n",
    "    '''\n",
    "    data, labels = dataFun()\n",
    "    d, n = data.shape\n",
    "    if draw:\n",
    "        ax = plot_data(data, labels)\n",
    "        def hook(params):\n",
    "            (th, th0) = params\n",
    "            if refresh: plot_data(data, labels, ax, clear = True)\n",
    "            plot_separator(ax, th, th0)\n",
    "            #print('th', th.T, 'th0', th0)\n",
    "            plt.pause(0.05)\n",
    "            if pause: input('go?')\n",
    "    else:\n",
    "        hook = None\n",
    "    th, th0 = learner(data, labels, hook = hook, params = learner_params)\n",
    "    print(\"Final score\", float(score(data, labels, th, th0)) / n)\n",
    "    print(\"Params\", np.transpose(th), th0)\n",
    "\n",
    "expected_perceptron = [(np.array([[-9.0], [18.0]]), np.array([[2.0]])),(np.array([[0.0], [-3.0]]), np.array([[0.0]]))]\n",
    "expected_averaged = [(np.array([[-9.0525], [17.5825]]), np.array([[1.9425]])),(np.array([[1.47], [-1.7275]]), np.array([[0.985]]))]\n",
    "datasets = [super_simple_separable_through_origin,xor]\n",
    "\n",
    "def incorrect(expected,result):\n",
    "    print(\"Test Failed.\")\n",
    "    print(\"Your code output \",result)\n",
    "    print(\"Expected \",expected)\n",
    "    print(\"\\n\")\n",
    "\n",
    "def correct():\n",
    "    print(\"Passed! \\n\")\n",
    "\n",
    "\n",
    "def test_perceptron(perceptron):\n",
    "    '''\n",
    "    Checks perceptron theta and theta0 values for 100 iterations\n",
    "    '''\n",
    "    for index in range(len(datasets)):\n",
    "        data, labels = datasets[index]()\n",
    "        th,th0 = perceptron(data, labels, {\"T\": 100})\n",
    "        expected_th,expected_th0 = expected_perceptron[index]\n",
    "        print(\"-----------Test Perceptron \"+str(index)+\"-----------\")\n",
    "        if((th==expected_th).all() and (th0==expected_th0).all()):\n",
    "            correct()\n",
    "        else:\n",
    "            incorrect(\"th: \"+str(expected_th.tolist())+\", th0: \"+str(expected_th0.tolist()), \"th: \"+str(th.tolist())+\", th0: \"+str(th0.tolist()))\n",
    "    \n",
    "def test_averaged_perceptron(averaged_perceptron):\n",
    "    '''\n",
    "    Checks average perceptron theta and theta0 values for 100 iterations\n",
    "    '''\n",
    "    for index in range(2):\n",
    "        data, labels = datasets[index]()\n",
    "        th,th0 = averaged_perceptron(data, labels, {\"T\": 100})\n",
    "        expected_th,expected_th0 = expected_averaged[index]\n",
    "        print(\"-----------Test Averaged Perceptron \"+str(index)+\"-----------\")\n",
    "        if((th==expected_th).all() and (th0==expected_th0).all()):\n",
    "            correct()\n",
    "        else:\n",
    "            incorrect(\"th: \"+str(expected_th.tolist())+\", th0: \"+str(expected_th0.tolist()), \"th: \"+str(th.tolist())+\", th0: \"+str(th0.tolist()))\n",
    "        \n",
    "def test_eval_classifier(eval_classifier,perceptron):\n",
    "    '''\n",
    "    Checks your classifier's performance on data1\n",
    "    '''\n",
    "    expected = [0.5333333333333333,0.6333333333333333]\n",
    "    dataset_train = [(data1,labels1),(data2,labels2)]\n",
    "    for index in range(len(dataset_train)):\n",
    "        data_train,labels_train = dataset_train[index]\n",
    "        #print(data_train,labels_train)\n",
    "        result = eval_classifier(perceptron, data_train, labels_train,data2,labels2)\n",
    "        print(\"-----------Test Eval Classifier \"+str(index)+\"-----------\")\n",
    "        if(result==expected[index]):\n",
    "            correct()\n",
    "        else:\n",
    "            incorrect(expected[index],result)\n",
    "\n",
    "def test_eval_learning_alg(eval_learning_alg,perceptron):\n",
    "    '''\n",
    "    Checks your learning algorithm's performance on big_data\n",
    "    eval_learning_alg method for evaluating learning algorithm\n",
    "    perceptron your perceptron learning algorithm method\n",
    "    '''\n",
    "    expected = 0.5599999999999999\n",
    "    result = eval_learning_alg(perceptron, gen_big_data(), 10, 10, 5)\n",
    "    print(\"-----------Test Eval Learning Algo-----------\")\n",
    "    if result == expected:\n",
    "        correct()\n",
    "    else:\n",
    "        incorrect(expected,result)\n",
    "        \n",
    "def test_xval_learning_alg(xval_learning_alg,perceptron):\n",
    "    '''\n",
    "    Checks your learning algorithm's performance on big_data using cross validation\n",
    "    xval_learning_alg method for evaluating learning algorithm using cross validation\n",
    "    perceptron your perceptron learning algorithm method\n",
    "    '''\n",
    "    expected = 0.61\n",
    "    result=xval_learning_alg(perceptron, big_data, big_data_labels, 5)\n",
    "    print(\"-----------Test Cross-eval Learning Algo-----------\")\n",
    "    if result == expected:\n",
    "        correct()\n",
    "    else:\n",
    "        incorrect(expected,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Code\n",
    "This section contains code written for homework assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Perceptron 0-----------\n",
      "Passed! \n",
      "\n",
      "-----------Test Perceptron 1-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_th_formatted = lambda th_long: (np.array([th_long[0,:-1]]).T, np.array([[th_long[0,-1]]]))\n",
    "\n",
    "def perceptron(data, labels, params={}, hook=None):\n",
    "    # if T not in params, default to 100\n",
    "    data_dim, data_amt = data.shape\n",
    "    T = params.get('T', 100)\n",
    "    th = np.zeros((1,data_dim + 1))\n",
    "    data = np.append(data, np.ones((1, data_amt)), axis=0)\n",
    "    for t in range(T):\n",
    "        err = False\n",
    "        for i_d, d in enumerate(data.T):\n",
    "            l = labels[0, i_d]\n",
    "            d = np.array([d])\n",
    "            sign = np.sign(l*th.dot(d.T))\n",
    "            if sign <= 0:\n",
    "                err = True\n",
    "                th += l*d\n",
    "            if hook:\n",
    "                hook(get_th_formatted(th))\n",
    "        if not err:\n",
    "            return get_th_formatted(th)\n",
    "    return get_th_formatted(th)\n",
    "    \n",
    "#Visualization of perceptron, comment in the next three lines to see your perceptron code in action:\n",
    "'''\n",
    "for datafn in (super_simple_separable_through_origin,super_simple_separable):\n",
    "    data, labels = datafn()\n",
    "    test_linear_classifier(datafn,perceptron,draw=True)\n",
    "'''\n",
    "\n",
    "#Test Cases:\n",
    "\n",
    "test_perceptron(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaged Perceptron Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Averaged Perceptron 0-----------\n",
      "Passed! \n",
      "\n",
      "-----------Test Averaged Perceptron 1-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def averaged_perceptron(data, labels, params={}, hook=None):\n",
    "    # if T not in params, default to 100\n",
    "    data_dim, data_amt = data.shape\n",
    "    T = params.get('T', 100)\n",
    "    th = np.zeros((data_dim, 1))\n",
    "    th0 = np.zeros((1,1))\n",
    "    ths = np.zeros((data_dim, 1))\n",
    "    th0s = np.zeros((1,1))\n",
    "    \n",
    "    for t in range(T):\n",
    "        for i_d, d in enumerate(data.T):\n",
    "            l = labels[0, i_d]\n",
    "            d = np.array([d])\n",
    "            if l*(d.dot(th)+th0) <= 0:\n",
    "                th += l*d.T\n",
    "                th0 += l\n",
    "            ths += th\n",
    "            th0s += th0\n",
    "        if hook:\n",
    "            hook((ths/(data_amt*(t+1)), th0s/(data_amt*(t+1))))\n",
    "    return (ths/(data_amt*T), th0s/(data_amt*T))\n",
    "\n",
    "#Test Cases:\n",
    "test_averaged_perceptron(averaged_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Classifier and Training Algorithm Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Eval Classifier 0-----------\n",
      "Passed! \n",
      "\n",
      "-----------Test Eval Classifier 1-----------\n",
      "Passed! \n",
      "\n",
      "-----------Test Eval Learning Algo-----------\n",
      "Passed! \n",
      "\n",
      "-----------Test Cross-eval Learning Algo-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def eval_classifier(learner, data_train, labels_train, data_test, labels_test):\n",
    "    th, th0 = learner(data_train, labels_train)\n",
    "    test_score = score(data_test, labels_test, th, th0)\n",
    "    return test_score/(labels_test.shape[1])\n",
    "    \n",
    "\n",
    "\n",
    "#Test cases:\n",
    "test_eval_classifier(eval_classifier,perceptron)\n",
    "\n",
    "def eval_learning_alg(learner, data_gen, n_train, n_test, it):\n",
    "    scores = 0\n",
    "    for i in range(it):\n",
    "        data_train, labels_train = data_gen(n_train)\n",
    "        data_test, labels_test = data_gen(n_test)\n",
    "        scores += eval_classifier(learner, data_train, labels_train, data_test, labels_test)\n",
    "    return scores/it\n",
    "\n",
    "\n",
    "#Test cases:\n",
    "test_eval_learning_alg(eval_learning_alg,perceptron)\n",
    "\n",
    "def xval_learning_alg(learner, data, labels, k):\n",
    "    #cross validation of learning algorithm\n",
    "    data_partitioned = np.array_split(data, k, axis=1)\n",
    "    labels_partitioned = np.array_split(labels, k, axis=1)\n",
    "    score = 0\n",
    "    for i in range(k):\n",
    "        data_test = data_partitioned[i]\n",
    "        labels_test = labels_partitioned[i]\n",
    "        data_train = np.delete(data_partitioned, i, axis=0)\n",
    "        data_train = np.concatenate(data_train, axis=1)\n",
    "        labels_train = np.delete(labels_partitioned, i, axis=0)\n",
    "        labels_train = np.concatenate(labels_train, axis=1)\n",
    "        score += eval_classifier(learner, data_train, labels_train, data_test, labels_test)\n",
    "    return score/k\n",
    "\n",
    "\n",
    "#Test cases:\n",
    "test_xval_learning_alg(xval_learning_alg,perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computations required for homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7565000000000002\n"
     ]
    }
   ],
   "source": [
    "print(eval_learning_alg(perceptron, gen_flipped_lin_separable(pflip=.1), 20, 20, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8105000000000001\n"
     ]
    }
   ],
   "source": [
    "print(eval_learning_alg(averaged_perceptron, gen_flipped_lin_separable(pflip=.1), 20, 20, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5815\n"
     ]
    }
   ],
   "source": [
    "print(eval_learning_alg(perceptron, gen_flipped_lin_separable(pflip=.25), 20, 20, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6230000000000002\n"
     ]
    }
   ],
   "source": [
    "print(eval_learning_alg(averaged_perceptron, gen_flipped_lin_separable(pflip=.25), 20, 20, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_learning_alg_modified(learner, data_gen, n_train, n_test, it):\n",
    "    scores = 0\n",
    "    for i in range(it):\n",
    "        data_train, labels_train = data_gen(n_train)\n",
    "        scores += eval_classifier(learner, data_train, labels_train, data_train, labels_train)\n",
    "    return scores/it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8175\n"
     ]
    }
   ],
   "source": [
    "print(eval_learning_alg_modified(perceptron, gen_flipped_lin_separable(pflip=.1), 20, 20, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8519999999999998\n"
     ]
    }
   ],
   "source": [
    "print(eval_learning_alg_modified(averaged_perceptron, gen_flipped_lin_separable(pflip=.1), 20, 20, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6545000000000001\n"
     ]
    }
   ],
   "source": [
    "print(eval_learning_alg_modified(perceptron, gen_flipped_lin_separable(pflip=.25), 20, 20, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7240000000000001\n"
     ]
    }
   ],
   "source": [
    "print(eval_learning_alg_modified(averaged_perceptron, gen_flipped_lin_separable(pflip=.25), 20, 20, 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
