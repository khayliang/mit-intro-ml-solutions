{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 Part 1\n",
    "The code block below contains required code for the homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing code_for_hw03\n",
      "Imported tidy_plot, plot_separator, plot_data, plot_nonlin_sep, cv, rv, y, positive, score\n",
      "Datasets: super_simple_separable_through_origin(), super_simple_separable(), xor(), xor_more()\n",
      "Tests for part 2: test_linear_classifier_with_features, mul, make_polynomial_feature_fun, \n",
      "                  test_with_features\n",
      "Also loaded: perceptron, one_hot_internal, test_one_hot\n"
     ]
    }
   ],
   "source": [
    "# Implement perceptron, average perceptron, and pegasos\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import pdb\n",
    "import itertools\n",
    "import operator\n",
    "import functools\n",
    "\n",
    "print(\"Importing code_for_hw03\")\n",
    "\n",
    "######################################################################\n",
    "# Plotting\n",
    "\n",
    "def tidy_plot(xmin, xmax, ymin, ymax, center = False, title = None,\n",
    "                 xlabel = None, ylabel = None):\n",
    "    plt.ion()\n",
    "    plt.figure(facecolor=\"white\")\n",
    "    ax = plt.subplot()\n",
    "    if center:\n",
    "        ax.spines['left'].set_position('zero')\n",
    "        ax.spines['right'].set_color('none')\n",
    "        ax.spines['bottom'].set_position('zero')\n",
    "        ax.spines['top'].set_color('none')\n",
    "        ax.spines['left'].set_smart_bounds(True)\n",
    "        ax.spines['bottom'].set_smart_bounds(True)\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "    else:\n",
    "        ax.spines[\"top\"].set_visible(False)    \n",
    "        ax.spines[\"right\"].set_visible(False)    \n",
    "        ax.get_xaxis().tick_bottom()  \n",
    "        ax.get_yaxis().tick_left()\n",
    "    eps = .05\n",
    "    plt.xlim(xmin-eps, xmax+eps)\n",
    "    plt.ylim(ymin-eps, ymax+eps)\n",
    "    if title: ax.set_title(title)\n",
    "    if xlabel: ax.set_xlabel(xlabel)\n",
    "    if ylabel: ax.set_ylabel(ylabel)\n",
    "    return ax\n",
    "\n",
    "def plot_separator(ax, th, th_0):\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    ymin,ymax = ax.get_ylim()\n",
    "    pts = []\n",
    "    eps = 1.0e-6\n",
    "    # xmin boundary crossing is when xmin th[0] + y th[1] + th_0 = 0\n",
    "    # that is, y = (-th_0 - xmin th[0]) / th[1]\n",
    "    if abs(th[1,0]) > eps:\n",
    "        pts += [np.array([x, (-th_0 - x * th[0,0]) / th[1,0]]) \\\n",
    "                                                        for x in (xmin, xmax)]\n",
    "    if abs(th[0,0]) > 1.0e-6:\n",
    "        pts += [np.array([(-th_0 - y * th[1,0]) / th[0,0], y]) \\\n",
    "                                                         for y in (ymin, ymax)]\n",
    "    in_pts = []\n",
    "    for p in pts:\n",
    "        if (xmin-eps) <= p[0] <= (xmax+eps) and \\\n",
    "           (ymin-eps) <= p[1] <= (ymax+eps):\n",
    "            duplicate = False\n",
    "            for p1 in in_pts:\n",
    "                if np.max(np.abs(p - p1)) < 1.0e-6:\n",
    "                    duplicate = True\n",
    "            if not duplicate:\n",
    "                in_pts.append(p)\n",
    "    if in_pts and len(in_pts) >= 2:\n",
    "        # Plot separator\n",
    "        vpts = np.vstack(in_pts)\n",
    "        ax.plot(vpts[:,0], vpts[:,1], 'k-', lw=2)\n",
    "        # Plot normal\n",
    "        vmid = 0.5*(in_pts[0] + in_pts[1])\n",
    "        scale = np.sum(th*th)**0.5\n",
    "        diff = in_pts[0] - in_pts[1]\n",
    "        dist = max(xmax-xmin, ymax-ymin)\n",
    "        vnrm = vmid + (dist/10)*(th.T[0]/scale)\n",
    "        vpts = np.vstack([vmid, vnrm])\n",
    "        ax.plot(vpts[:,0], vpts[:,1], 'k-', lw=2)\n",
    "        # Try to keep limits from moving around\n",
    "        ax.set_xlim((xmin, xmax))\n",
    "        ax.set_ylim((ymin, ymax))\n",
    "    else:\n",
    "        print('Separator not in plot range')\n",
    "\n",
    "def plot_data(data, labels, ax = None, clear = False,\n",
    "                  xmin = None, xmax = None, ymin = None, ymax = None):\n",
    "    if ax is None:\n",
    "        if xmin == None: xmin = np.min(data[0, :]) - 0.5\n",
    "        if xmax == None: xmax = np.max(data[0, :]) + 0.5\n",
    "        if ymin == None: ymin = np.min(data[1, :]) - 0.5\n",
    "        if ymax == None: ymax = np.max(data[1, :]) + 0.5\n",
    "        ax = tidy_plot(xmin, xmax, ymin, ymax)\n",
    "\n",
    "        x_range = xmax - xmin; y_range = ymax - ymin\n",
    "        if .1 < x_range / y_range < 10:\n",
    "            ax.set_aspect('equal')\n",
    "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "    elif clear:\n",
    "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "        ax.clear()\n",
    "    else:\n",
    "        xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "    colors = np.choose(labels > 0, cv(['r', 'g']))[0]\n",
    "    ax.scatter(data[0,:], data[1,:], c = colors,\n",
    "                    marker = 'o', s=50, edgecolors = 'none')\n",
    "    # Seems to occasionally mess up the limits\n",
    "    ax.set_xlim(xlim); ax.set_ylim(ylim)\n",
    "    ax.grid(True, which='both')\n",
    "    #ax.axhline(y=0, color='k')\n",
    "    #ax.axvline(x=0, color='k')\n",
    "    return ax\n",
    "\n",
    "# Must either specify limits or existing ax\n",
    "def plot_nonlin_sep(predictor, ax = None, xmin = None , xmax = None,\n",
    "                        ymin = None, ymax = None, res = 30):\n",
    "    if ax is None:\n",
    "        ax = tidy_plot(xmin, xmax, ymin, ymax)\n",
    "    else:\n",
    "        if xmin == None:\n",
    "            xmin, xmax = ax.get_xlim()\n",
    "            ymin, ymax = ax.get_ylim()\n",
    "        else:\n",
    "            ax.set_xlim((xmin, xmax))\n",
    "            ax.set_ylim((ymin, ymax))\n",
    "\n",
    "    cmap = colors.ListedColormap(['black', 'white'])\n",
    "    bounds=[-2,0,2]\n",
    "    norm = colors.BoundaryNorm(bounds, cmap.N)            \n",
    "            \n",
    "    ima = np.array([[predictor(x1i, x2i) \\\n",
    "                         for x1i in np.linspace(xmin, xmax, res)] \\\n",
    "                         for x2i in np.linspace(ymin, ymax, res)])\n",
    "    im = ax.imshow(np.flipud(ima), interpolation = 'none',\n",
    "                       extent = [xmin, xmax, ymin, ymax],\n",
    "                       cmap = cmap, norm = norm)\n",
    "\n",
    "######################################################################\n",
    "#   Utilities\n",
    "\n",
    "# Takes a list of numbers and returns a column vector:  n x 1\n",
    "def cv(value_list):\n",
    "    return np.transpose(rv(value_list))\n",
    "\n",
    "# Takes a list of numbers and returns a row vector: 1 x n\n",
    "def rv(value_list):\n",
    "    return np.array([value_list])\n",
    "\n",
    "# x is dimension d by 1\n",
    "# th is dimension d by 1\n",
    "# th0 is a scalar\n",
    "# return a 1 by 1 matrix\n",
    "def y(x, th, th0):\n",
    "   return np.dot(np.transpose(th), x) + th0\n",
    "\n",
    "# x is dimension d by 1\n",
    "# th is dimension d by 1\n",
    "# th0 is dimension 1 by 1\n",
    "# return 1 by 1 matrix of +1, 0, -1\n",
    "def positive(x, th, th0):\n",
    "   return np.sign(y(x, th, th0))\n",
    "\n",
    "# data is dimension d by n\n",
    "# labels is dimension 1 by n\n",
    "# ths is dimension d by 1\n",
    "# th0s is dimension 1 by 1\n",
    "# return 1 by 1 matrix of integer indicating number of data points correct for\n",
    "# each separator.\n",
    "def score(data, labels, th, th0):\n",
    "   return np.sum(positive(data, th, th0) == labels)\n",
    "\n",
    "######################################################################\n",
    "#   Data Sets\n",
    "\n",
    "# Return d = 2 by n = 4 data matrix and 1 x n = 4 label matrix\n",
    "def super_simple_separable_through_origin():\n",
    "    X = np.array([[2, 3, 9, 12],\n",
    "                  [5, 1, 6, 5]])\n",
    "    y = np.array([[1, -1, 1, -1]])\n",
    "    return X, y\n",
    "\n",
    "def super_simple_separable():\n",
    "    X = np.array([[2, 3, 9, 12],\n",
    "                  [5, 2, 6, 5]])\n",
    "    y = np.array([[1, -1, 1, -1]])\n",
    "    return X, y\n",
    "\n",
    "def xor():\n",
    "    X = np.array([[1, 2, 1, 2],\n",
    "                  [1, 2, 2, 1]])\n",
    "    y = np.array([[1, 1, -1, -1]])\n",
    "    return X, y\n",
    "\n",
    "def xor_more():\n",
    "    X = np.array([[1, 2, 1, 2, 2, 4, 1, 3],\n",
    "                  [1, 2, 2, 1, 3, 1, 3, 3]])\n",
    "    y = np.array([[1, 1, -1, -1, 1, 1, -1, -1]])\n",
    "    return X, y\n",
    "\n",
    "######################################################################\n",
    "#   Tests for part 2:  features\n",
    "\n",
    "# Make it take miscellaneous args and pass into learner\n",
    "def test_linear_classifier_with_features(dataFun, learner, feature_fun,\n",
    "                             draw = True, refresh = True, pause = True):\n",
    "    raw_data, labels = dataFun()\n",
    "    data = feature_fun(raw_data) if feature_fun else raw_data\n",
    "    if draw:\n",
    "        ax = plot_data(raw_data, labels)\n",
    "        def hook(params):\n",
    "            (th, th0) = params\n",
    "            plot_nonlin_sep(\n",
    "                lambda x1,x2: int(positive(feature_fun(cv([x1, x2])), th, th0)),\n",
    "                ax = ax)\n",
    "            plot_data(raw_data, labels, ax)\n",
    "            plt.pause(0.05)\n",
    "            print('th', th.T, 'th0', th0)\n",
    "            if pause: input('press enter here to continue:')\n",
    "    else:\n",
    "        hook = None\n",
    "    th, th0 = learner(data, labels, hook = hook)\n",
    "    if hook: hook((th, th0))\n",
    "    print(\"Final score\", int(score(data, labels, th, th0)))\n",
    "    print(\"Params\", np.transpose(th), th0)\n",
    "\n",
    "def mul(seq):\n",
    "    return functools.reduce(operator.mul, seq, 1)\n",
    "\n",
    "def make_polynomial_feature_fun(order):\n",
    "    # raw_features is d by n\n",
    "    # return is k by n where k = sum_{i = 0}^order  multichoose(d, i)\n",
    "    def f(raw_features):\n",
    "        d, n = raw_features.shape\n",
    "        result = []   # list of column vectors\n",
    "        for j in range(n):\n",
    "            features = []\n",
    "            for o in range(order+1):\n",
    "                indexTuples = \\\n",
    "                          itertools.combinations_with_replacement(range(d), o)\n",
    "                for it in indexTuples:\n",
    "                    features.append(mul(raw_features[i, j] for i in it))\n",
    "            result.append(cv(features))\n",
    "        return np.hstack(result)\n",
    "    return f\n",
    "\n",
    "def test_with_features(dataFun, order = 2, draw=True, pause=True):\n",
    "    test_linear_classifier_with_features(\n",
    "        dataFun,                        # data\n",
    "        perceptron,                     # learner\n",
    "        make_polynomial_feature_fun(order), # feature maker\n",
    "        draw=draw,\n",
    "        pause=pause)\n",
    "\n",
    "# Perceptron algorithm with offset.\n",
    "# data is dimension d by n\n",
    "# labels is dimension 1 by n\n",
    "# T is a positive integer number of steps to run\n",
    "def perceptron(data, labels, params = {}, hook = None):\n",
    "    T = params.get('T', 100)\n",
    "    (d, n) = data.shape\n",
    "    m = 0\n",
    "    theta = np.zeros((d, 1)); theta_0 = np.zeros((1, 1))\n",
    "    dataset_margin = 1\n",
    "    for t in range(T):\n",
    "        dataset_margin = 1\n",
    "        for i in range(n):\n",
    "            x = data[:,i:i+1]\n",
    "            y = labels[:,i:i+1]\n",
    "            dataset_margin = min(dataset_margin, y * positive(x, theta, theta_0))\n",
    "            if y * positive(x, theta, theta_0) <= 0.0:\n",
    "                m += 1\n",
    "                theta = theta + y * x\n",
    "                theta_0 = theta_0 + y\n",
    "                if hook: hook((theta, theta_0))\n",
    "        if dataset_margin > 0:\n",
    "            break\n",
    "\n",
    "    return theta, theta_0, dataset_margin, m\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################################\n",
    "#   Tests for part 2D:  Encoding discrete values\n",
    "\n",
    "def one_hot_internal(x, k):\n",
    "    # Make an empty column vector\n",
    "    v = np.zeros((k, 1))\n",
    "    # Set an entry to 1\n",
    "    v[x-1, 0] = 1\n",
    "    return v\n",
    "\n",
    "def test_one_hot(sub):\n",
    "    if one_hot_internal(3, 5).tolist() == sub(3, 5).tolist() and one_hot_internal(4, 7).tolist() == sub(4, 7).tolist():\n",
    "        print(\"Passed! \\n\")\n",
    "    else: print(\"Test Failed\")\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "print(\"Imported tidy_plot, plot_separator, plot_data, plot_nonlin_sep, cv, rv, y, positive, score\")\n",
    "print(\"Datasets: super_simple_separable_through_origin(), super_simple_separable(), xor(), xor_more()\")\n",
    "print(\"Tests for part 2: test_linear_classifier_with_features, mul, make_polynomial_feature_fun, \")\n",
    "print(\"                  test_with_features\")\n",
    "print(\"Also loaded: perceptron, one_hot_internal, test_one_hot\")\n",
    "\n",
    "######################################################################\n",
    "#   Example for part 3B) test_with_features()\n",
    "#test_with_features(super_simple_separable, 2, draw=True, pause=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Code\n",
    "Code block below contains code written for homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistakes made: 666696\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[200, 800, 200, 800],\n",
    "             [0.2,  0.2,  0.8,  0.8]])\n",
    "labels = np.array([[-1, -1, 1, 1]])\n",
    "\n",
    "# DON'T RUN: TOTAL MISTAKES: 666696\n",
    "# _, _, _, mistakes = perceptron(data, labels, params={\"T\": 400000})\n",
    "mistakes = 666696\n",
    "print(\"Mistakes made: \" + str(mistakes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistakes made: 7\n"
     ]
    }
   ],
   "source": [
    "data_1 = data * np.array([[0.001],[1]])\n",
    "_, _, _, mistakes = perceptron(data_1, labels)\n",
    "\n",
    "print(\"Mistakes made: \" + str(mistakes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta:  [[-2.]]\n",
      "theta_0:  [[7.]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[2, 3,  4,  5]])\n",
    "labels = np.array([[1, 1, -1, -1]])\n",
    "\n",
    "th, th_0, _, _ = perceptron(data, labels)\n",
    "print(\"theta: \", th)\n",
    "print(\"theta_0: \",th_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "def one_hot(x, k):\n",
    "    vec = np.zeros((k, 1))\n",
    "    vec[x-1] = 1\n",
    "    return vec\n",
    "\n",
    "print(one_hot(2, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_arr(data, k):\n",
    "    d, n = data.shape\n",
    "    one_hot_data = []\n",
    "    for i in range(n):\n",
    "        v_d = data[:,i]\n",
    "        v = one_hot(v_d, k)\n",
    "        one_hot_data.append(v[:, 0])\n",
    "    \n",
    "    one_hot_data = np.array(one_hot_data)\n",
    "    return one_hot_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [ 0.]] [[0.]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_data = one_hot_arr(data, 6)\n",
    "th, th_0, _, _ = perceptron(one_hot_data, labels)\n",
    "print(th, th_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [ 1.]\n",
      " [ 1.]] [[0.]]\n"
     ]
    }
   ],
   "source": [
    "new_data = np.array([[1,2,3,4,5,6]])\n",
    "new_labels = np.array([[1,1,-1,-1,1,1]])\n",
    "one_hot_new_data = one_hot_arr(new_data, 6)\n",
    "\n",
    "th, th_0, _, _ = perceptron(one_hot_new_data, new_labels, params={\"T\": 200})\n",
    "print(th, th_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  [3, 66, 231, 496, 861, 1326]\n"
     ]
    }
   ],
   "source": [
    "deg = [1,10,20,30,40,50]\n",
    "feature_len = []\n",
    "for d in deg:\n",
    "    x = np.array([[1,2]]).T\n",
    "    feat_fn = make_polynomial_feature_fun(d)\n",
    "    feature_len.append(len(feat_fn(x)))\n",
    "print(\"Number of features: \", feature_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for the `super_simple_separable_through_origin` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th:  [[-9.]\n",
      " [18.]] th_0:  [[2.]]\n",
      "margin:  1 ,mistakes:  12\n"
     ]
    }
   ],
   "source": [
    "data, labels = super_simple_separable_through_origin()\n",
    "th, th0, margin_1, mistake_1 = perceptron(data, labels)\n",
    "print(\"th: \", th, \"th_0: \", th0)\n",
    "print(\"margin: \", margin_1, \",mistakes: \", mistake_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for the `super_simple_separable` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th:  [[-24.]\n",
      " [ 37.]] th_0:  [[-3.]]\n",
      "margin:  1 ,mistakes:  47\n"
     ]
    }
   ],
   "source": [
    "data, labels = super_simple_separable()\n",
    "th, th0, margin_2, mistake_2 = perceptron(data, labels)\n",
    "print(\"th: \", th, \"th_0: \", th0)\n",
    "print(\"margin: \", margin_2, \",mistakes: \", mistake_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for the `xor` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th:  [[ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-5.]\n",
      " [11.]\n",
      " [-5.]] th_0:  [[1.]]\n",
      "margin:  1 ,mistakes:  65\n"
     ]
    }
   ],
   "source": [
    "data_xor, labels_xor = xor()\n",
    "# Use polynomial feature mapping of with degree 2\n",
    "th, th0, margin_3, mistake_3 = perceptron(make_polynomial_feature_fun(2)(data_xor), labels_xor)\n",
    "print(\"th: \", th, \"th_0: \", th0)\n",
    "print(\"margin: \", margin_3, \",mistakes: \", mistake_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for the `xor_more` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th:  [[ -78.]\n",
      " [  28.]\n",
      " [ -39.]\n",
      " [  72.]\n",
      " [ 248.]\n",
      " [ -19.]\n",
      " [  76.]\n",
      " [-522.]\n",
      " [ 476.]\n",
      " [-153.]] th_0:  [[-78.]]\n",
      "margin:  1 ,mistakes:  2202\n"
     ]
    }
   ],
   "source": [
    "data_xor_more, labels_xor_more = xor_more()\n",
    "# Use polynomial feature mapping of with degree 3\n",
    "th, th0, margin_4, mistake_4 = perceptron(\\\n",
    "                                          make_polynomial_feature_fun(3)(data_xor_more), \\\n",
    "                                          labels_xor_more, \\\n",
    "                                         params={\"T\": 50000})\n",
    "print(\"th: \", th, \"th_0: \", th0)\n",
    "print(\"margin: \", margin_4, \",mistakes: \", mistake_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
