{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Feature Representation for Car Data\n",
    "In this lab, the goal is to classify car models into either having >28 miles per gallon, or <28 miles per gallon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mpg  cylinders  displacement  horsepower  weight  acceleration  model_year  \\\n",
      "0   -1          8         304.0         193    4732          18.5          70   \n",
      "1   -1          8         307.0         200    4376          15.0          70   \n",
      "2   -1          8         360.0         215    4615          14.0          70   \n",
      "3   -1          8         318.0         210    4382          13.5          70   \n",
      "4   -1          8         350.0         180    3664          11.0          73   \n",
      "\n",
      "   origin          car_name  \n",
      "0       1          hi 1200d  \n",
      "1       1         chevy c20  \n",
      "2       1         ford f250  \n",
      "3       1        dodge d200  \n",
      "4       1  oldsmobile omega  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cars_pd = pd.read_csv('auto-mpg.csv')\n",
    "print(cars_pd.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "- Remove unused data points\n",
    "- Extract outcomes\n",
    "- Standardize numerical data\n",
    "- Encode origin country using one hot encoding\n",
    "- Separate data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize a 2d array\n",
    "def standardize(arr, axis=0):\n",
    "    mean = np.mean(arr, axis=axis)\n",
    "    std = np.std(arr, axis=axis)\n",
    "    arr = (arr - mean)/std\n",
    "    return arr\n",
    "\n",
    "# one hot encoding of discrete number column\n",
    "def one_hot_encoding(arr):\n",
    "    arr = arr.astype(int)\n",
    "    codes = np.zeros((arr.size, np.max(arr) + 1))\n",
    "    codes[np.arange(arr.size).astype(int), arr.astype(int)] = 1    \n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_arr = cars_pd.to_numpy()\n",
    "np.random.shuffle(cars_arr)\n",
    "# get outcomes\n",
    "outcomes = np.array([cars_arr[:, 0]])\n",
    "cars_arr = np.delete(cars_arr, 0, axis=1)\n",
    "\n",
    "# remove useless rows: car_name\n",
    "cars_arr = np.delete(cars_arr, -1, axis=1)\n",
    "\n",
    "# set type of data to np.float64\n",
    "cars_arr = cars_arr.astype(np.float64)\n",
    "\n",
    "# remove origin from array for one hot encoding\n",
    "origin_col = cars_arr[:, -1]\n",
    "cars_arr = np.delete(cars_arr, -1, axis=1)\n",
    "\n",
    "origin_col -= 1\n",
    "one_hot_origin =one_hot_encoding(origin_col)\n",
    "\n",
    "# standardize\n",
    "std_cars_arr = standardize(cars_arr.astype(np.float64), axis=0)\n",
    "\n",
    "# append one hot origin encoding to std_cars_arr\n",
    "data = np.concatenate((std_cars_arr, one_hot_origin), axis=1)\n",
    "\n",
    "# Build train and test set\n",
    "data_len = data.shape[0]\n",
    "split_idx = int(data_len*0.9)\n",
    "\n",
    "train_data = data[:split_idx, :].T\n",
    "train_outcomes = outcomes[:, :split_idx]\n",
    "\n",
    "test_data = data[split_idx:, :].T\n",
    "test_outcomes = outcomes[:, split_idx:]\n",
    "\n",
    "train_data_unprocessed = cars_arr[:split_idx, :].T\n",
    "test_data_unprocessed = cars_arr[split_idx:, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data (9, 352)\n",
      "shape of training outcomes (1, 352)\n",
      "shape of test data (9, 40)\n",
      "shape of test outcomes (1, 40)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of training data\", train_data.shape)\n",
    "print(\"shape of training outcomes\", train_outcomes.shape)\n",
    "print(\"shape of test data\", test_data.shape)\n",
    "print(\"shape of test outcomes\", test_outcomes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting\n",
    "Computing accuracy of perceptron for data that's been processed and unprocessed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_perceptron(data, labels, params={}, hook=None):\n",
    "    # if T not in params, default to 100\n",
    "    data_dim, data_amt = data.shape\n",
    "    T = params.get('T', 100)\n",
    "    th = np.zeros((data_dim, 1))\n",
    "    th0 = np.zeros((1,1))\n",
    "    ths = np.zeros((data_dim, 1))\n",
    "    th0s = np.zeros((1,1))\n",
    "    \n",
    "    for t in range(T):\n",
    "        for i_d, d in enumerate(data.T):\n",
    "            l = labels[0, i_d]\n",
    "            d = np.array([d])\n",
    "            if l*(d.dot(th)+th0) <= 0:\n",
    "                th += l*d.T\n",
    "                th0 += l\n",
    "            ths += th\n",
    "            th0s += th0\n",
    "        if hook:\n",
    "            hook((ths/(data_amt*(t+1)), th0s/(data_amt*(t+1))))\n",
    "    return (ths/(data_amt*T), th0s/(data_amt*T))\n",
    "\n",
    "def compute_score(th, th0, test_data, test_outcomes):\n",
    "    test_data.T.dot()\n",
    "\n",
    "\n",
    "def y(x, th, th0):\n",
    "    '''\n",
    "    x is dimension d by 1\n",
    "    th is dimension d by 1\n",
    "    th0 is a scalar\n",
    "    return a 1 by 1 matrix\n",
    "    '''\n",
    "    return np.dot(np.transpose(th), x) + th0\n",
    "\n",
    "def positive(x, th, th0):\n",
    "    '''\n",
    "    x is dimension d by 1\n",
    "    th is dimension d by 1\n",
    "    th0 is dimension 1 by 1\n",
    "    return 1 by 1 matrix of +1, 0, -1\n",
    "    '''\n",
    "    return np.sign(y(x, th, th0))\n",
    "\n",
    "def score(data, labels, th, th0):\n",
    "    '''\n",
    "    data is dimension d by n\n",
    "    labels is dimension 1 by n\n",
    "    ths is dimension d by 1\n",
    "    th0s is dimension 1 by 1\n",
    "    return 1 by 1 matrix of integer indicating number of data points correct for\n",
    "    each separator.\n",
    "    '''\n",
    "    return np.sum(positive(data, th, th0) == labels)\n",
    "\n",
    "def eval_classifier(learner, data_train, labels_train, data_test, labels_test):\n",
    "    th, th0 = learner(data_train, labels_train)\n",
    "    test_score = score(data_test, labels_test, th, th0)\n",
    "    return test_score/(labels_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "th, th0 = averaged_perceptron(train_data, train_outcomes)\n",
    "th_unprocessed, th0_unprocessed = averaged_perceptron(train_data_unprocessed, train_outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "Test perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score for processed data:  0.925\n",
      "Test score for unprocessed data:  0.85\n"
     ]
    }
   ],
   "source": [
    "test_score = score(test_data, test_outcomes, th, th0)\n",
    "test_score_unprocessed = score(test_data_unprocessed, test_outcomes, th_unprocessed, th0_unprocessed)\n",
    "print(\"Test score for processed data: \", test_score/test_data.shape[1])\n",
    "print(\"Test score for unprocessed data: \", test_score_unprocessed/test_data.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
