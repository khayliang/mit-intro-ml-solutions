{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Margin Maximization with SVM\n",
    "In this homework, we will work towards implement a support vector machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# utility functions\n",
    "\n",
    "def rv(x):\n",
    "    \"\"\"\n",
    "    Converts given numpy array into row vector\n",
    "    :param x: np 1d array or 2d vector array  \n",
    "    \"\"\"\n",
    "    try:\n",
    "        r, c = x.shape\n",
    "        if r > 0:\n",
    "            return x.T\n",
    "        else:\n",
    "            return x \n",
    "    except:\n",
    "        return np.array([x])\n",
    "\n",
    "def cv(x):\n",
    "    \"\"\"\n",
    "    Converts given numpy array into column vector\n",
    "    :param x: np 1d array or 2d vector array\n",
    "    \"\"\"\n",
    "    try:\n",
    "        r, c = x.shape\n",
    "        if c > 0:\n",
    "            return x.T\n",
    "        else:\n",
    "            return x \n",
    "    except:\n",
    "        return np.array([x])\n",
    "\n",
    "def magnitude(x):\n",
    "    return np.linalg.norm(x)\n",
    "\n",
    "def signed_dist(point, th, th0):\n",
    "    return (th.T.dot(cv(point)) + th0)/magnitude(th)\n",
    "\n",
    "def margin(point, label, th, th0):\n",
    "    return label * signed_dist(point, th, th0)[0,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_margin(data, labels, th, th0):\n",
    "    \"\"\"\n",
    "    Sum up all the margins of the points in a dataset w.r.t a hyperplane\n",
    "\n",
    "    :param data: dataset shape (i,N) where N is no. of points\n",
    "    :param labels: labels corresponding to dataset with shape (1, N)\n",
    "    :param th: parameters of the hyperplane with shape (1, i)\n",
    "    :param th0: offset of hyperplane\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for idx, point in enumerate(data.T):\n",
    "        total += margin(point, labels[0, idx], th, th0)\n",
    "    return total\n",
    "\n",
    "def min_margin(data, labels, th, th0):\n",
    "    \"\"\"\n",
    "    Get the minimum margin of the points in a dataset w.r.t a hyperplane\n",
    "    \n",
    "    :param data: dataset shape (i,N) where N is no. of points\n",
    "    :param labels: labels corresponding to dataset with shape (1, N)\n",
    "    :param th: parameters of the hyperplane with shape (1, i)\n",
    "    :param th0: offset of hyperplane\n",
    "    \"\"\"\n",
    "    mn = np.inf\n",
    "    for idx, point in enumerate(data.T):\n",
    "        mgn = margin(point, labels[0, idx], th, th0)\n",
    "        mn = min(mn, mgn)\n",
    "    return mn\n",
    "\n",
    "def max_margin(data, labels, th, th0):\n",
    "    \"\"\"\n",
    "    Get the maximum margin of the points in a dataset w.r.t a hyperplane\n",
    "    \n",
    "    :param data: dataset shape (i,N) where N is no. of points\n",
    "    :param labels: labels corresponding to dataset with shape (1, N)\n",
    "    :param th: parameters of the hyperplane with shape (1, i)\n",
    "    :param th0: offset of hyperplane\n",
    "    \"\"\"\n",
    "    mx = -np.inf\n",
    "    for idx, point in enumerate(data.T):\n",
    "        mgn = margin(point, labels[0, idx], th, th0)\n",
    "        mx = max(mx, mgn)\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data provided for homework for calculating min, max, sum of margin\n",
    "\n",
    "data = np.array([[1, 2, 1, 2, 10, 10.3, 10.5, 10.7],\n",
    "                 [1, 1, 2, 2,  2,  2,  2, 2]])\n",
    "labels = np.array([[-1, -1, 1, 1, 1, 1, 1, 1]])\n",
    "blue_th = np.array([[0, 1]]).T\n",
    "blue_th0 = -1.5\n",
    "red_th = np.array([[1, 0]]).T\n",
    "red_th0 = -2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margin sum, blue:  4.0\n",
      "Margin min, blue:  0.5\n",
      "Margin max, blue:  0.5\n",
      "Margin sum, red:  31.5\n",
      "Margin min, red:  -1.5\n",
      "Margin max, red:  8.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Margin sum, blue: \", sum_margin(data, labels, blue_th, blue_th0))\n",
    "print(\"Margin min, blue: \", min_margin(data, labels, blue_th, blue_th0))\n",
    "print(\"Margin max, blue: \", max_margin(data, labels, blue_th, blue_th0))\n",
    "print(\"Margin sum, red: \", sum_margin(data, labels, red_th, red_th0))\n",
    "print(\"Margin min, red: \", min_margin(data, labels, red_th, red_th0))\n",
    "print(\"Margin max, red: \", max_margin(data, labels, red_th, red_th0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hinge loss\n",
    "Hinge loss is a loss function to maximize the minimum margin of a dataset to a hyperplane. Let:\n",
    "- $\\theta, \\theta_0$: parameters for hyperplane\n",
    "- $\\gamma(x, y, \\theta, \\theta_0)$: margin of a point $x, y$ to hyperplane\n",
    "- $\\gamma_{\\text{ref}}$: minimum margin acceptable\n",
    "\n",
    "The equation for hinge loss is defined as:\n",
    "$$\n",
    "L_h\\Big(\\frac{\\gamma(x,y,\\theta, \\theta_0)}{\\gamma_{\\text{ref}}}\\Big) = \\begin{cases} 1- \\frac{\\gamma(x,y,\\theta, \\theta_0)}{\\gamma_{\\text{ref}}} & \\text{ if } \\gamma(x, y, \\theta, \\theta_0) < \\gamma_{\\text{ref}} \\\\ 0 & \\text{ otherwise}\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge(v):\n",
    "    return max(0, 1-v)\n",
    "\n",
    "def hinge_loss(x,y, th, th0):\n",
    "    \"\"\"\n",
    "    Calculate hinge loss for a point on a given hyperplane\n",
    "    \n",
    "    :param x: data of point\n",
    "    :param y: label of point\n",
    "    :param th: hyperplane parameters\n",
    "    :param th0: hyperplane offset\n",
    "    \"\"\"\n",
    "    mgn = margin(x, y, th, th0)\n",
    "    return hinge(mgn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7999999999999998, 0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "# data provided for calculating hinge loss\n",
    "\n",
    "data = np.array([[1.1, 1, 4],[3.1, 1, 2]])\n",
    "labels = np.array([[1, -1, -1]])\n",
    "th = np.array([[1, 1]]).T\n",
    "th0 = -4\n",
    "\n",
    "hinge_arr = []\n",
    "for idx, data in enumerate(data.T):\n",
    "    l = hinge_loss(data, labels[0, idx], th, th0, math.sqrt(2)/2)\n",
    "    hinge_arr.append(l)\n",
    "    \n",
    "print(hinge_arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Gradient Descent\n",
    "We will now implement a generic gradient descent function, gd, that has the following input arguments:\n",
    "\n",
    "- f: a function whose input is an x, a column vector, and returns a scalar.\n",
    "- df: a function whose input is an x, a column vector, and returns a column vector representing the gradient of f at x.\n",
    "- x0: an initial value of x\n",
    "- x, x0, which is a column vector.\n",
    "- step_size_fn: a function that is given the iteration index (an integer) and returns a step size.\n",
    "- max_iter: the number of iterations to perform\n",
    "\n",
    "Our function gd returns a tuple:\n",
    "\n",
    "- x: the value at the final step\n",
    "- fs: the list of values of f found during all the iterations (including f(x0))\n",
    "- xs: the list of values of x found during all the iterations (including x0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(f, df, x0, step_size_fn, max_iter):\n",
    "    x_curr = x0\n",
    "    fs = [f(x_curr)]\n",
    "    xs = [x_curr]\n",
    "    for i in range(max_iter):\n",
    "        x_new = x_curr - df(x_curr)*step_size_fn(i)\n",
    "        val_new = f(x_new)\n",
    "        \n",
    "        fs.append(val_new)\n",
    "        xs.append(x_new)\n",
    "        \n",
    "        x_curr = x_new\n",
    "    return (x_curr, fs, xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Numerical Gradient \n",
    "We can compute the $i^{th}$ component of $\\nabla f(x_0)$ through the following approximation:\n",
    "$$\n",
    "\\frac{f(x_0 + \\delta) - f(x_0 - \\delta)}{2\\delta} \\text{ where }\\delta>0\n",
    "$$\n",
    "\n",
    "Implement this as a function num_grad that takes as arguments the objective function f and a value of delta, and returns a new function that takes an x (a column vector of parameters) and returns a gradient column vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_grad(f, delta=0.001):\n",
    "    def df(x):\n",
    "        r, c = x.shape\n",
    "        g = np.zeros((1,r))\n",
    "        for idx in range(len(x)):\n",
    "            d = np.zeros((1,r))\n",
    "            d[0, idx] = delta\n",
    "            gi = (f(x + d.T) - f(x - d.T))/(2*delta)\n",
    "            g[0, idx] = gi\n",
    "        return g.T    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating minimum of function\n",
    "Write a function minimize that takes only a function f and uses this function and numerical gradient descent to return the local minimum. We have provided you with our implementations of num_grad and gd, so you should not redefine them in the code box below. You may use the default of delta=0.001 for num_grad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize(f, x0, step_size_fn, max_iter):\n",
    "    return gd(f, num_grad(f, delta=0.001), x0, step_size_fn, max_iter)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective Function of SVM\n",
    "Implement the single-argument function hinge, which computes $L_h$, and use that to implement hinge loss for a data point and separator. Using the latter function, implement the SVM objective. Note that these functions should work for matrix/vector arguments, so that we can compute the objective for a whole dataset with one call. The objective function is defined as:\n",
    "$$\n",
    "J(\\theta, \\theta_0) = \\frac{1}{n}\\Big( \\sum^n_{i=1} L_h(y^i(x^i\\cdot\\theta + \\theta_0)) \\Big ) + \\lambda \\Vert\\theta\\Vert^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is dxn, y is 1xn, th is dx1, th0 is 1x1, lam is a scalar\n",
    "def svm_obj(x, y, th, th0, lam):\n",
    "    d, n = x.shape\n",
    "    sum_err = 0\n",
    "    for idx, d in enumerate(x.T):\n",
    "        label = y[0, idx]\n",
    "        sum_err += hinge_loss(d, label, th, th0)\n",
    "    training_err = sum_err/n\n",
    "    return training_err + lam*magnitude(th)**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient of individual parameters of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.06], [0.3], [0.0]]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the gradient of hinge(v) with respect to v.\n",
    "def d_hinge(v):\n",
    "    v[v < 1] = -1\n",
    "    v[v >= 1] = 0\n",
    "    return v\n",
    "\n",
    "# Returns the gradient of hinge_loss(x, y, th, th0) with respect to th\n",
    "def d_hinge_loss_th(x, y, th, th0):\n",
    "    return d_hinge((x.T.dot(th) + th0)*y.T).T*y*x\n",
    "\n",
    "\n",
    "# Returns the gradient of hinge_loss(x, y, th, th0) with respect to th0\n",
    "def d_hinge_loss_th0(x, y, th, th0):\n",
    "    return d_hinge((x.T.dot(th) + th0)*y.T).T*y\n",
    "\n",
    "# Returns the gradient of svm_obj(x, y, th, th0) with respect to th\n",
    "def d_svm_obj_th(x, y, th, th0, lam):\n",
    "    d, n = x.shape\n",
    "    d_hinge_loss_th_sum = np.sum(d_hinge_loss_th(x, y, th, th0), axis=1)\n",
    "    return ((1/n)*d_hinge_loss_th_sum + 2*lam*th.T).T\n",
    "\n",
    "# Returns the gradient of svm_obj(x, y, th, th0) with respect to th0\n",
    "def d_svm_obj_th0(x, y, th, th0, lam):\n",
    "    d, n = x.shape\n",
    "    d_hinge_loss_th0_sum = np.array([np.sum(d_hinge_loss_th0(x, y, th, th0), axis=1)]).T\n",
    "    return (1/n)*d_hinge_loss_th0_sum\n",
    "\n",
    "# Returns the full gradient as a single vector (which includes both th, th0)\n",
    "def svm_obj_grad(X, y, th, th0, lam):\n",
    "    d_th = d_svm_obj_th(X, y, th, th0, lam)\n",
    "    d_th0 = d_svm_obj_th0(X, y, th, th0, lam)\n",
    "    return np.vstack((d_th, d_th0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Gradient Descent for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_svm_min(data, labels, lam):\n",
    "    d, n = data.shape\n",
    "    def f(x):\n",
    "        th = np.array([x[:-1, 0]]).T\n",
    "        th0 = np.array([[x[-1, 0]]])\n",
    "        return svm_obj(data, labels, th, th0, lam)\n",
    "    def df(x):\n",
    "        th = np.array([x[:-1, 0]]).T\n",
    "        th0 = np.array([[x[-1, 0]]])\n",
    "        return svm_obj_grad(data, labels, th, th0, lam)\n",
    "    def svm_min_step_size_fn(i):\n",
    "        return 2/(i+1)**0.5\n",
    "    return gd(f, df, np.zeros((d+1, 1)), svm_min_step_size_fn, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
